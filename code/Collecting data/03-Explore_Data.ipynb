{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would train my model with two diffrenet datasets:\n",
    "    - Cornell movie dialogue corpus\n",
    "    - Reddit comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two datasets store bunch of sentences , and that is something we don't have to explore for now. I already know how the data looks. However, it is worthwhile to explore how complex the datasets are. The complexity could suggest how we should approach to get the right result still considering some of restrictions.\n",
    "\n",
    "note: For each dataset, there are two files (from, to) contains the same number of lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read file data\n",
    "def load_data(path):\n",
    "    input_file = os.path.join(path)\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1- Cornell movie dialogue corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read movies data\n",
    "mov_from_text = load_data('../data/datasets/movies/train.from')\n",
    "mov_to_text = load_data('../data/datasets/movies/train.to')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies Dataset Summary:\n",
      "number of unique words in Comment sample sentences(roughly measured/without any preprocessing): 89266\n",
      "\n",
      "Comment sentences\n",
      "\t- number of sentences: 108136\n",
      "\t- avg. number of words in a sentence: 10.644826884663757\n",
      "Replay sentences\n",
      "\t- number of sentences: 108136\n",
      "\t- avg. number of words in a sentence: 10.046524746615374\n",
      "\n",
      "Sample sentences range from 0 to 5\n",
      "[1-th] sentence\n",
      "\tComment: All the suites are about the same.\n",
      "\tReplay: Come on. Just tell me. It'll save all the trouble of you showing me all the rooms.\n",
      "\n",
      "[2-th] sentence\n",
      "\tComment: Honestly, the suites are all about the same.\n",
      "\tReplay: What if I gave you forty?\n",
      "\n",
      "[3-th] sentence\n",
      "\tComment: It's as good a suite as we have, unless you want two bedrooms.\n",
      "\tReplay: No. That's cool. Bring me back eighty.\n",
      "\n",
      "[4-th] sentence\n",
      "\tComment: Thank you, sir.\n",
      "\tReplay: Where's the place to go tonight?\n",
      "\n",
      "[5-th] sentence\n",
      "\tComment: As far as...?\n",
      "\tReplay: Nightlife. Where's the hot ass?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Movies Dataset Summary:')\n",
    "print('number of unique words in Comment sample sentences\\\n",
    "(roughly measured/without any preprocessing): {}'.format(len(set(mov_from_text.split()))))\n",
    "print()\n",
    "\n",
    "from_sentences = mov_from_text.split('\\n')\n",
    "print('Comment sentences')\n",
    "print('\\t- number of sentences: {}'.format(len(from_sentences)))\n",
    "print('\\t- avg. number of words in a sentence: {}'.format(np.average([len(sentence.split()) for sentence in from_sentences])))\n",
    "\n",
    "to_sentences = mov_to_text.split('\\n')\n",
    "print('Replay sentences')\n",
    "print('\\t- number of sentences: {}'.format(len(to_sentences)))\n",
    "print('\\t- avg. number of words in a sentence: {}'.format(np.average([len(sentence.split()) for sentence in to_sentences])))\n",
    "print()\n",
    "\n",
    "\n",
    "side_by_side_sentences = list(zip(from_sentences, to_sentences))[:5]\n",
    "print('Sample sentences range from {} to {}'.format(0, 5))\n",
    "\n",
    "for index, sentence in enumerate(side_by_side_sentences):\n",
    "    from_sent, to_sent = sentence\n",
    "    print('[{}-th] sentence'.format(index+1))\n",
    "    print('\\tComment: {}'.format(from_sent))\n",
    "    print('\\tReplay: {}'.format(to_sent))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2- Reddit comments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read Reddit data\n",
    "red_from_text = load_data('../data/datasets/reddit/train3.from')\n",
    "red_to_text = load_data('../data/datasets/reddit/train3.to')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reddit Dataset Summary:\n",
      "number of unique words in Comment sample sentences(roughly measured/without any preprocessing): 229481\n",
      "\n",
      "* Comment sentences\n",
      "\t- number of sentences: 100001\n",
      "\t- avg. number of words in a sentence: 30.96661033389666\n",
      "* Replay sentences\n",
      "\t- number of sentences: 100001\n",
      "\t- avg. number of words in a sentence: 29.35738642613574\n",
      "\n",
      "Sample sentences range from 0 to 5\n",
      "[1-th] sentence\n",
      "\tComment: but that's only considering he *didn't* have Harry's blood to start with, right? meaning in the book as is he still wouldn't have killed Harry even if he used another wand because of Lily's protection in Harry's blood\n",
      "\tReplay: Yup. newlinechar No Harry's blood + any other wand = dead Harry.\n",
      "\n",
      "[2-th] sentence\n",
      "\tComment: Very sexy story.  I was about to get fuller erect myself.\n",
      "\tReplay: thank you for responding. I love sharing my life and seeing how it helps others :)\n",
      "\n",
      "[3-th] sentence\n",
      "\tComment: I won't be happy until I can get a t shit that fits a WWI biplane because that's what I identify as.\n",
      "\tReplay: It must be a bitch to find an appropriate lavatory for you\n",
      "\n",
      "[4-th] sentence\n",
      "\tComment: Haha, thanks for your reply.newlinechar I wish they'd hurry up then, Britta was only truly awful for like 1.5 episodes? Unless I'm remembering incorrectly (It's been a few years since I last watched that show).\n",
      "\tReplay: Britta was bad the first season, picked up the next 2 and then was awful the last 3\n",
      "\n",
      "[5-th] sentence\n",
      "\tComment: Loved it when he showed up in John Wick.\n",
      "\tReplay: Made my day too.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Reddit Dataset Summary:')\n",
    "print('number of unique words in Comment sample sentences\\\n",
    "(roughly measured/without any preprocessing): {}'.format(len(set(red_from_text.split()))))\n",
    "print()\n",
    "\n",
    "from_sentences = red_from_text.split('\\n')\n",
    "print('* Comment sentences')\n",
    "print('\\t- number of sentences: {}'.format(len(from_sentences)))\n",
    "print('\\t- avg. number of words in a sentence: {}'.format(np.average([len(sentence.split()) for sentence in from_sentences])))\n",
    "\n",
    "to_sentences = red_to_text.split('\\n')\n",
    "print('* Replay sentences')\n",
    "print('\\t- number of sentences: {}'.format(len(to_sentences)))\n",
    "print('\\t- avg. number of words in a sentence: {}'.format(np.average([len(sentence.split()) for sentence in to_sentences])))\n",
    "print()\n",
    "\n",
    "\n",
    "side_by_side_sentences = list(zip(from_sentences, to_sentences))[:5]\n",
    "print('Sample sentences range from {} to {}'.format(0, 5))\n",
    "\n",
    "for index, sentence in enumerate(side_by_side_sentences):\n",
    "    from_sent, to_sent = sentence\n",
    "    print('[{}-th] sentence'.format(index+1))\n",
    "    print('\\tComment: {}'.format(from_sent))\n",
    "    print('\\tReplay: {}'.format(to_sent))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
